{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9757e00d",
   "metadata": {},
   "source": [
    "# Water Potability Model Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1ca005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/work')\n",
    "\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import mlflow.mleap\n",
    "\n",
    "import mleap.pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession,DataFrame\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "from pipeline import feature_pipeline_builder\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fb42188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "ml.combust.mleap#mleap-spark-base_2.11 added as a dependency\n",
      "ml.combust.mleap#mleap-spark_2.11 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ff4472d3-8b9c-41a0-b67c-9d0fbcbda7c4;1.0\n",
      "\tconfs: [default]\n",
      "\tfound ml.combust.mleap#mleap-spark-base_2.11;0.17.0 in central\n",
      "\tfound ml.combust.mleap#mleap-runtime_2.11;0.17.0 in central\n",
      "\tfound ml.combust.mleap#mleap-core_2.11;0.17.0 in central\n",
      "\tfound ml.combust.mleap#mleap-base_2.11;0.17.0 in central\n",
      "\tfound ml.combust.mleap#mleap-tensor_2.11;0.17.0 in central\n",
      "\tfound io.spray#spray-json_2.11;1.3.2 in central\n",
      "\tfound com.github.rwl#jtransforms;2.4.0 in central\n",
      "\tfound ml.combust.bundle#bundle-ml_2.11;0.17.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.5.1 in central\n",
      "\tfound com.thesamet.scalapb#scalapb-runtime_2.11;0.7.1 in central\n",
      "\tfound com.thesamet.scalapb#lenses_2.11;0.7.0-test2 in central\n",
      "\tfound com.lihaoyi#fastparse_2.11;1.0.0 in central\n",
      "\tfound com.lihaoyi#fastparse-utils_2.11;1.0.0 in central\n",
      "\tfound com.lihaoyi#sourcecode_2.11;0.1.4 in central\n",
      "\tfound com.jsuereth#scala-arm_2.11;2.0 in central\n",
      "\tfound com.typesafe#config;1.3.0 in central\n",
      "\tfound commons-io#commons-io;2.5 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.11.12 in central\n",
      "\tfound ml.combust.bundle#bundle-hdfs_2.11;0.17.0 in central\n",
      "\tfound ml.combust.mleap#mleap-spark_2.11;0.17.0 in central\n",
      "downloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-spark-base_2.11/0.17.0/mleap-spark-base_2.11-0.17.0.jar ...\n",
      "\t[SUCCESSFUL ] ml.combust.mleap#mleap-spark-base_2.11;0.17.0!mleap-spark-base_2.11.jar (322ms)\n",
      "downloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-spark_2.11/0.17.0/mleap-spark_2.11-0.17.0.jar ...\n",
      "\t[SUCCESSFUL ] ml.combust.mleap#mleap-spark_2.11;0.17.0!mleap-spark_2.11.jar (341ms)\n",
      "downloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-runtime_2.11/0.17.0/mleap-runtime_2.11-0.17.0.jar ...\n",
      "\t[SUCCESSFUL ] ml.combust.mleap#mleap-runtime_2.11;0.17.0!mleap-runtime_2.11.jar (710ms)\n",
      "downloading https://repo1.maven.org/maven2/ml/combust/bundle/bundle-hdfs_2.11/0.17.0/bundle-hdfs_2.11-0.17.0.jar ...\n",
      "\t[SUCCESSFUL ] ml.combust.bundle#bundle-hdfs_2.11;0.17.0!bundle-hdfs_2.11.jar (58ms)\n",
      "downloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-core_2.11/0.17.0/mleap-core_2.11-0.17.0.jar ...\n",
      "\t[SUCCESSFUL ] ml.combust.mleap#mleap-core_2.11;0.17.0!mleap-core_2.11.jar (241ms)\n",
      "downloading https://repo1.maven.org/maven2/ml/combust/bundle/bundle-ml_2.11/0.17.0/bundle-ml_2.11-0.17.0.jar ...\n",
      "\t[SUCCESSFUL ] ml.combust.bundle#bundle-ml_2.11;0.17.0!bundle-ml_2.11.jar (363ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-io/commons-io/2.5/commons-io-2.5.jar ...\n",
      "\t[SUCCESSFUL ] commons-io#commons-io;2.5!commons-io.jar (84ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar ...\n",
      "\t[SUCCESSFUL ] org.scala-lang#scala-reflect;2.11.12!scala-reflect.jar (773ms)\n",
      "downloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-base_2.11/0.17.0/mleap-base_2.11-0.17.0.jar ...\n",
      "\t[SUCCESSFUL ] ml.combust.mleap#mleap-base_2.11;0.17.0!mleap-base_2.11.jar (57ms)\n",
      "downloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-tensor_2.11/0.17.0/mleap-tensor_2.11-0.17.0.jar ...\n",
      "\t[SUCCESSFUL ] ml.combust.mleap#mleap-tensor_2.11;0.17.0!mleap-tensor_2.11.jar (59ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/rwl/jtransforms/2.4.0/jtransforms-2.4.0.jar ...\n",
      "\t[SUCCESSFUL ] com.github.rwl#jtransforms;2.4.0!jtransforms.jar (181ms)\n",
      "downloading https://repo1.maven.org/maven2/io/spray/spray-json_2.11/1.3.2/spray-json_2.11-1.3.2.jar ...\n",
      "\t[SUCCESSFUL ] io.spray#spray-json_2.11;1.3.2!spray-json_2.11.jar(bundle) (91ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.5.1/protobuf-java-3.5.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.5.1!protobuf-java.jar(bundle) (258ms)\n",
      "downloading https://repo1.maven.org/maven2/com/thesamet/scalapb/scalapb-runtime_2.11/0.7.1/scalapb-runtime_2.11-0.7.1.jar ...\n",
      "\t[SUCCESSFUL ] com.thesamet.scalapb#scalapb-runtime_2.11;0.7.1!scalapb-runtime_2.11.jar (633ms)\n",
      "downloading https://repo1.maven.org/maven2/com/jsuereth/scala-arm_2.11/2.0/scala-arm_2.11-2.0.jar ...\n",
      "\t[SUCCESSFUL ] com.jsuereth#scala-arm_2.11;2.0!scala-arm_2.11.jar (71ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.3.0/config-1.3.0.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.3.0!config.jar(bundle) (85ms)\n",
      "downloading https://repo1.maven.org/maven2/com/thesamet/scalapb/lenses_2.11/0.7.0-test2/lenses_2.11-0.7.0-test2.jar ...\n",
      "\t[SUCCESSFUL ] com.thesamet.scalapb#lenses_2.11;0.7.0-test2!lenses_2.11.jar (63ms)\n",
      "downloading https://repo1.maven.org/maven2/com/lihaoyi/fastparse_2.11/1.0.0/fastparse_2.11-1.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.lihaoyi#fastparse_2.11;1.0.0!fastparse_2.11.jar (95ms)\n",
      "downloading https://repo1.maven.org/maven2/com/lihaoyi/fastparse-utils_2.11/1.0.0/fastparse-utils_2.11-1.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.lihaoyi#fastparse-utils_2.11;1.0.0!fastparse-utils_2.11.jar (63ms)\n",
      "downloading https://repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.11/0.1.4/sourcecode_2.11-0.1.4.jar ...\n",
      "\t[SUCCESSFUL ] com.lihaoyi#sourcecode_2.11;0.1.4!sourcecode_2.11.jar(bundle) (70ms)\n",
      ":: resolution report :: resolve 15238ms :: artifacts dl 4644ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.rwl#jtransforms;2.4.0 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.5.1 from central in [default]\n",
      "\tcom.jsuereth#scala-arm_2.11;2.0 from central in [default]\n",
      "\tcom.lihaoyi#fastparse-utils_2.11;1.0.0 from central in [default]\n",
      "\tcom.lihaoyi#fastparse_2.11;1.0.0 from central in [default]\n",
      "\tcom.lihaoyi#sourcecode_2.11;0.1.4 from central in [default]\n",
      "\tcom.thesamet.scalapb#lenses_2.11;0.7.0-test2 from central in [default]\n",
      "\tcom.thesamet.scalapb#scalapb-runtime_2.11;0.7.1 from central in [default]\n",
      "\tcom.typesafe#config;1.3.0 from central in [default]\n",
      "\tcommons-io#commons-io;2.5 from central in [default]\n",
      "\tio.spray#spray-json_2.11;1.3.2 from central in [default]\n",
      "\tml.combust.bundle#bundle-hdfs_2.11;0.17.0 from central in [default]\n",
      "\tml.combust.bundle#bundle-ml_2.11;0.17.0 from central in [default]\n",
      "\tml.combust.mleap#mleap-base_2.11;0.17.0 from central in [default]\n",
      "\tml.combust.mleap#mleap-core_2.11;0.17.0 from central in [default]\n",
      "\tml.combust.mleap#mleap-runtime_2.11;0.17.0 from central in [default]\n",
      "\tml.combust.mleap#mleap-spark-base_2.11;0.17.0 from central in [default]\n",
      "\tml.combust.mleap#mleap-spark_2.11;0.17.0 from central in [default]\n",
      "\tml.combust.mleap#mleap-tensor_2.11;0.17.0 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.11.12 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.protobuf#protobuf-java;3.5.0 by [com.google.protobuf#protobuf-java;3.5.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   21  |   20  |   20  |   1   ||   20  |   20  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ff4472d3-8b9c-41a0-b67c-9d0fbcbda7c4\n",
      "\tconfs: [default]\n",
      "\t20 artifacts copied, 0 already retrieved (16919kB/64ms)\n",
      "21/07/26 16:14:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder  \\\n",
    "    .config('spark.jars.packages', 'ml.combust.mleap:mleap-spark-base_2.11:0.17.0,ml.combust.mleap:mleap-spark_2.11:0.17.0') \\\n",
    "    .appName('ClassifierTraining')  \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde46dc",
   "metadata": {},
   "source": [
    "## Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "585a2ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+----------+\n",
      "|  ph|          Hardness|            Solids|       Chloramines|           Sulfate|      Conductivity|    Organic_carbon|  Trihalomethanes|         Turbidity|Potability|\n",
      "+----+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+----------+\n",
      "|null|  98.3679148956603| 28415.57583214058|10.558949998467961|  296.843207792478|505.24026927891407|12.882614472289333|85.32995534051292| 4.119087300328971|         1|\n",
      "|null|103.46475866009455| 27420.16742458204| 8.417305032089528|              null|485.97450045781375|11.351132730708514| 67.8699636759021| 4.620793451653219|         0|\n",
      "|null|108.91662923953173|14476.335695268315| 5.398162017711099|  281.198274407849| 512.2323064106689|15.013793389990155| 86.6714587149138| 3.895572062268123|         1|\n",
      "|null|113.17596460727073|  9943.92978526269| 6.337137942441213|354.29756524708256| 415.3383368798727| 19.67616854859483|23.07580599653685| 3.787475537347365|         1|\n",
      "|null| 114.7335449715346| 13677.99404000127| 9.981200455815905|441.82677662870003|  524.000355172102|11.384858471731945|71.15328465919002|3.2938483740192734|         1|\n",
      "+----+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/water_potability_train.csv'\n",
    "df_train = spark.read.csv(file_path,inferSchema=True, header=True)\n",
    "df_train = df_train.drop('_c0')\n",
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d7ddb9",
   "metadata": {},
   "source": [
    "## Load the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d2664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+----------+\n",
      "|  ph|          Hardness|            Solids|      Chloramines|           Sulfate|      Conductivity|    Organic_carbon|   Trihalomethanes|         Turbidity|Potability|\n",
      "+----+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+----------+\n",
      "|null|105.85926357195498| 37928.14217716675|5.609440345508508|              null|358.88876761151056|12.207108489369546| 71.11989017420973| 3.873853349593973|         0|\n",
      "|null|115.39297941167533| 46077.35848526223|5.289306681961538| 437.5922998268262| 422.0173564256122|10.809631953564008| 53.61703537004023| 4.212510849647721|         0|\n",
      "|null|118.98857909025189|14285.583854224515|7.804173553073094|  268.646940746221| 389.3755658712614| 12.70604896865791|53.928845767512236|3.5950171809576155|         0|\n",
      "|null|119.88581029792707|22331.237876497587|8.051538021964916|351.16142711715133| 472.0640909647271| 16.64281537247524| 62.64709100380799| 4.659394533911933|         0|\n",
      "|null|131.54774425866867|21626.497594539993|7.207846353642049|              null| 390.9550329818341| 14.84495477882956|26.505484036158983|  4.72812398548281|         1|\n",
      "+----+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/water_potability_test.csv'\n",
    "df_test = spark.read.csv(file_path,inferSchema=True, header=True)\n",
    "df_test = df_test.drop('_c0')\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44499a1",
   "metadata": {},
   "source": [
    "## Create the Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c7a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3\n",
    "prediction_col = 'Potability'\n",
    "feature_cols = ['ph','Hardness','Solids','Chloramines','Sulfate','Conductivity',\n",
    "               'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
    "\n",
    "assembler_out_col = 'feature_vector'\n",
    "scaler_out_col = 'scaled_features'\n",
    "expander_out_col = 'features'\n",
    "\n",
    "feature_pipeline = feature_pipeline_builder.create_feature_pipeline(feature_cols,\n",
    "                                                    assembler_out_col,\n",
    "                                                    scaler_out_col,\n",
    "                                                    expander_out_col, \n",
    "                                                    degree)\n",
    "\n",
    "feature_model = feature_pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67cb44c",
   "metadata": {},
   "source": [
    "### Transform the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92123332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|Potability|            features|\n",
      "+----------+--------------------+\n",
      "|         1|[-1.0191119363888...|\n",
      "|         0|[-1.0191119363888...|\n",
      "|         1|[-1.0191119363888...|\n",
      "|         1|[-1.0191119363888...|\n",
      "|         1|[-1.0191119363888...|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_with_features = feature_model.transform(df_train)\n",
    "train_expanded_features = train_with_features.select(prediction_col,expander_out_col)\n",
    "train_persisted = train_expanded_features.persist()\n",
    "train_expanded_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23854c04",
   "metadata": {},
   "source": [
    "## Model Experimentation with MLFlow\n",
    "### Set up Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ece521",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'water_potability'\n",
    "mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
    "mlflow.set_experiment(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b07c2",
   "metadata": {},
   "source": [
    "### Fit the Model to the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d7021d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(featuresCol=expander_out_col,labelCol=prediction_col, maxIter=10)\n",
    "fit_model = gbt.fit(train_persisted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657af399",
   "metadata": {},
   "source": [
    "### Transform the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba95cab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|Potability|            features|\n",
      "+----------+--------------------+\n",
      "|         0|[-1.0191119363888...|\n",
      "|         0|[-1.0191119363888...|\n",
      "|         0|[-1.0191119363888...|\n",
      "|         0|[-1.0191119363888...|\n",
      "|         1|[-1.0191119363888...|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_with_features = feature_model.transform(df_test)\n",
    "test_expanded_features = test_with_features.select(prediction_col, expander_out_col)\n",
    "test_persisted = test_expanded_features.persist()\n",
    "test_expanded_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3784c0bd",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "700a5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_model.transform(test_persisted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ddfc278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is :  0.5940165732390933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/26 16:15:04 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/07/26 16:15:04 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    }
   ],
   "source": [
    "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                       labelCol=prediction_col)\n",
    "results.select(prediction_col,'prediction')\n",
    "AUC = my_eval.evaluate(results)\n",
    "print(\"AUC score is : \",AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e34b9",
   "metadata": {},
   "source": [
    "## Add GBTClassifier to Pipeline Model and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8204b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = PipelineModel(stages = [feature_model , gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab04e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mlflow.spark.save_model(spark_model=final_pipeline,\n",
    "                        path='../models/water_potability_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed605ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
