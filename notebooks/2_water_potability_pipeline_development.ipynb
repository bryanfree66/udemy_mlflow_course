{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6e0b20",
   "metadata": {},
   "source": [
    "# Water Potability Pipeline Development Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3977c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/work')\n",
    "\n",
    "from handyspark import *\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler, PolynomialExpansion, StandardScaler\n",
    "\n",
    "# from pyspark.mllib.stat import Statistics\n",
    "#from pipeline import feature_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38dae191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/07/26 19:05:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e48dc8",
   "metadata": {},
   "source": [
    "## Step 2 - Feature Pipeline Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a908d7",
   "metadata": {},
   "source": [
    "### Make Test-Train Split\n",
    "\n",
    "It is important to make the test train split before doing any feature pipeline development. Giving your pipline prior knowledge of the test data is a form of data leakage that can introduce bias into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b1e5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 2675\n",
      "Test Dataset Count: 601\n"
     ]
    }
   ],
   "source": [
    "# Randomly split the the dataset into test and train.\n",
    "# Set the seed value for reproducability\n",
    "\n",
    "df = spark.read.csv('../data/water_potability.csv',inferSchema=True, header=True)\n",
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed = 42)\n",
    "print(\"Training Dataset Count: \" + str(df_train.count()))\n",
    "print(\"Test Dataset Count: \" + str(df_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26827a19",
   "metadata": {},
   "source": [
    "### Impute Missing Values\n",
    "\n",
    "Imputing missing values based on the value of the target column is somewhat difficult to do with Pyspark, so I am going to use a package called HandySpark which makes it easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5430eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[91m---------------------------------------------------------------------------\n",
      "HANDY EXCEPTION SUMMARY\n",
      "\u001b[0m\n",
      "Location: \"/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py\"\n",
      "Line\t: 1500\n",
      "Function: _validate_integer\n",
      "\u001b[1m\u001b[91mError\t: IndexError: single positional indexer is out-of-bounds\u001b[0m\n",
      "\u001b[1m\u001b[91m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "ename": "HandyException",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/handyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1923\u001b[0m                                 \u001b[0mcolnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m                             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/handyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfill\u001b[0;34m(self, continuous, categorical, strategy, *args)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fill_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/handyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__fill_self\u001b[0;34m(self, continuous, categorical, strategy)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imputed_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/handyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m_fill_values\u001b[0;34m(self, continuous, categorical, strategy)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mcolnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__stat_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/handyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mcolnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__stat_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/handyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__stat_to_dict\u001b[0;34m(self, colname, stat)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             return {clause: stat.query(raw_clause)[colname].iloc[0]\n\u001b[0m\u001b[1;32m    272\u001b[0m                     for clause, raw_clause in zip(self._strata_clauses, self._strata_raw_clauses)}\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/handyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             return {clause: stat.query(raw_clause)[colname].iloc[0]\n\u001b[0m\u001b[1;32m    272\u001b[0m                     for clause, raw_clause in zip(self._strata_clauses, self._strata_raw_clauses)}\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHandyException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/92486207.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoHandy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhdf_filled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Potability'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdf_filled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotHandy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Check for Missing Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/handyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2035\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mHandyException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mHandyException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m                     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraised\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHandyException\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "hdf = df_train.toHandy()\n",
    "\n",
    "\n",
    "#hdf_filled = hdf.stratify(['Potability']).fill(continuous=['ph'], strategy=['mean'])\n",
    "#df_train = hdf_filled.notHandy()\n",
    "\n",
    "# Check for Missing Data\n",
    "#df_train.select(*(F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).show()\n",
    "\n",
    "#imputer = Imputer(\n",
    "#    inputCols=['ph', 'Sulfate', 'Trihalomethanes'],\n",
    "#    outputCols=['ph', 'Sulfate', 'Trihalomethanes']\n",
    "#)\n",
    "#df_imputed = imputer.setStrategy(\"mean\").fit(df_train).transform(df_train)\n",
    "#df_imputed.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443a01c",
   "metadata": {},
   "source": [
    "### Create Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0960ba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Features=DenseVector([98.3679, 28415.5758, 10.5589, 505.2403, 12.8826, 4.1191])),\n",
       " Row(Features=DenseVector([103.4648, 27420.1674, 8.4173, 485.9745, 11.3511, 4.6208])),\n",
       " Row(Features=DenseVector([108.9166, 14476.3357, 5.3982, 512.2323, 15.0138, 3.8956]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_assembler = VectorAssembler(\n",
    "    inputCols=['Hardness','Solids','Chloramines','Conductivity','Organic_carbon',\n",
    "               'Turbidity'],\n",
    "    outputCol='Features'\n",
    ")\n",
    "df_features = vec_assembler.transform(df_imputed)\n",
    "df_features.select('Features').take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd261c4a",
   "metadata": {},
   "source": [
    "### Scale the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a2d468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ScaledFeatures=DenseVector([-2.9992, 0.7207, 2.1483, 0.9852, -0.4139, 0.1916])),\n",
       " Row(ScaledFeatures=DenseVector([-2.844, 0.6065, 0.8047, 0.7464, -0.8819, 0.8329])),\n",
       " Row(ScaledFeatures=DenseVector([-2.678, -0.8779, -1.0894, 1.0718, 0.2373, -0.0941]))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler(\n",
    "    inputCol='Features', outputCol='ScaledFeatures',\n",
    "    withStd=True, withMean=True\n",
    ")\n",
    "\n",
    "scalerFit = scaler.fit(df_features)\n",
    "\n",
    "df_features_scaled = scalerFit.transform(df_features)\n",
    "df_features_scaled.select('ScaledFeatures').take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d05c65",
   "metadata": {},
   "source": [
    "### Perform Polynomial Feature Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eaa977a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PolynomialFeatures=DenseVector([-2.9992, 8.9953, -26.9789, 0.7207, -2.1615, 6.4829, 0.5194, -1.5578, 0.3743, 2.1483, -6.4432, 19.3247, 1.5483, -4.6436, 1.1158, 4.6152, -13.842, 3.3262, 9.9149, 0.9852, -2.9547, 8.8619, 0.71, -2.1295, 0.5117, 2.1164, -6.3476, 1.5253, 4.5467, 0.9705, -2.9109, 0.6995, 2.085, 0.9561, -0.4139, 1.2414, -3.7232, -0.2983, 0.8947, -0.215, -0.8892, 2.6669, -0.6408, -1.9103, -0.4078, 1.223, -0.2939, -0.876, -0.4017, 0.1713, -0.5138, 0.1235, 0.368, 0.1688, -0.0709, 0.1916, -0.5748, 1.7238, 0.1381, -0.4142, 0.0995, 0.4117, -1.2347, 0.2967, 0.8844, 0.1888, -0.5662, 0.1361, 0.4056, 0.186, -0.0793, 0.2379, -0.0572, -0.1704, -0.0781, 0.0328, 0.0367, -0.1101, 0.0265, 0.0789, 0.0362, -0.0152, 0.007]))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_feature_exp = PolynomialExpansion(degree=3, inputCol=\"ScaledFeatures\", outputCol=\"PolynomialFeatures\")\n",
    "poly_features = poly_feature_exp.transform(df_features_scaled)\n",
    "poly_features.select('PolynomialFeatures').take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1cdd8",
   "metadata": {},
   "source": [
    "## Test Pipeline Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2192116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ExpandedFeatures=DenseVector([-0.0, 0.0, -0.0, -2.9992, 0.0, -0.0, 8.9953, -0.0, -26.9789, 0.7207, -0.0, 0.0, -2.1615, 0.0, 6.4829, 0.5194, -0.0, -1.5578, 0.3743, 2.1483, -0.0, 0.0, -6.4432, 0.0, 19.3247, 1.5483, -0.0, -4.6436, 1.1158, 4.6152, -0.0, -13.842, 3.3262, 9.9149, -1.0138, 0.0, -0.0, 3.0405, -0.0, -9.1191, -0.7306, 0.0, 2.1913, -0.5265, -2.1779, 0.0, 6.5319, -1.5696, -4.6787, 1.0277, -0.0, -3.0824, 0.7407, 2.2079, -1.0419, 0.9852, -0.0, 0.0, -2.9547, 0.0, 8.8619, 0.71, -0.0, -2.1295, 0.5117, 2.1164, -0.0, -6.3476, 1.5253, 4.5467, -0.9987, 0.0, 2.9954, -0.7198, -2.1456, 1.0125, 0.9705, -0.0, -2.9109, 0.6995, 2.085, -0.9839, 0.9561, -0.4139, 0.0, -0.0, 1.2414, -0.0, -3.7232, -0.2983, 0.0, 0.8947, -0.215, -0.8892, 0.0, 2.6669, -0.6408, -1.9103, 0.4196, -0.0, -1.2585, 0.3024, 0.9014, -0.4254, -0.4078, 0.0, 1.223, -0.2939, -0.876, 0.4134, -0.4017, 0.1713, -0.0, -0.5138, 0.1235, 0.368, -0.1737, 0.1688, -0.0709, 1.2052, -0.0, 0.0, -3.6145, 0.0, 10.8408, 0.8685, -0.0, -2.605, 0.626, 2.589, -0.0, -7.7651, 1.8659, 5.5621, -1.2217, 0.0, 3.6643, -0.8805, -2.6247, 1.2386, 1.1873, -0.0, -3.5609, 0.8557, 2.5506, -1.2036, 1.1697, -0.4988, 0.0, 1.4961, -0.3595, -1.0716, 0.5057, -0.4914, 0.2065, 1.4524, -0.0, -4.3561, 1.0467, 3.1202, -1.4724, 1.4309, -0.6012, 1.7504, 0.1916, -0.0, 0.0, -0.5748, 0.0, 1.7238, 0.1381, -0.0, -0.4142, 0.0995, 0.4117, -0.0, -1.2347, 0.2967, 0.8844, -0.1943, 0.0, 0.5827, -0.14, -0.4174, 0.1969, 0.1888, -0.0, -0.5662, 0.1361, 0.4056, -0.1914, 0.186, -0.0793, 0.0, 0.2379, -0.0572, -0.1704, 0.0804, -0.0781, 0.0328, 0.2309, -0.0, -0.6927, 0.1664, 0.4961, -0.2341, 0.2275, -0.0956, 0.2783, 0.0367, -0.0, -0.1101, 0.0265, 0.0789, -0.0372, 0.0362, -0.0152, 0.0443, 0.007]))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['ph','Hardness','Solids','Chloramines','Sulfate','Conductivity',\n",
    "               'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
    "assembler_out_col = 'Features'\n",
    "scaler_out_col = 'ScaledFeatures'\n",
    "expander_out_col = 'ExpandedFeatures'\n",
    "degree = 3\n",
    "\n",
    "pipeline = feature_pipeline.create_feature_pipeline(df_train, feature_cols, assembler_out_col, \n",
    "                                                    scaler_out_col, expander_out_col, degree)\n",
    "\n",
    "pipeline.transform(df_train).select('ExpandedFeatures').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e775f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
